import numpy as np
import torch
import torch.nn.functional as F
from sklearn.decomposition import PCA
from torch import nn


def test(x):
    pca = PCA(n_components=2)
    y = pca.fit_transform(x)
    cps = pca.components_
    mean = pca.mean_
    var = pca.explained_variance_

    a = x - pca.mean_
    a = np.dot(a, pca.components_.T)
    z = pca.transform(x)
    print(y)
    print(a)
    print(z)


def test_1():
    pca = {"cps": [[-0.07007598876953125, -0.059544868767261505], [0.116305410861969, -0.1387345790863037],
                   [0.07236921042203903, 0.050865039229393005], [0.4767988920211792, -0.22880375385284424],
                   [0.036880653351545334, 0.08171586692333221], [0.06305509805679321, 0.4423563480377197],
                   [0.06917717307806015, 0.1071055680513382], [-0.14741377532482147, -0.22783613204956055],
                   [0.05395783856511116, 0.44438478350639343], [-0.2074669748544693, -0.15746358036994934],
                   [0.057075560092926025, 0.062063612043857574], [-0.05999426916241646, 0.1584659069776535],
                   [-0.3183119297027588, 0.5398557782173157], [-0.17333601415157318, -0.0818282961845398],
                   [0.4507070481777191, -0.06938624382019043], [-0.574299693107605, -0.31990793347358704]],
           "mean": [-0.12453163415193558, 0.5213608741760254, -0.4491022527217865, 1.2416912317276, 0.1858503818511963,
                    -0.4432697296142578, 0.08431007713079453, -0.31855061650276184, 0.8044213056564331,
                    -0.2757808566093445, -0.5284936428070068, 0.5226341485977173, -0.02583455480635166,
                    -0.31993168592453003, -0.5548665523529053, 0.8761393427848816],
           "var": [3.045815944671631, 1.384323000907898]}
    center = [[-0.21875625848770142, 0.33786195516586304, -0.2835361063480377, 1.1223207712173462, 0.22375379502773285,
               0.34607404470443726, 0.2903978228569031, -0.6913787126541138, 1.4803714752197266, -0.6075961589813232,
               -0.34696894884109497, 0.7912510633468628, 0.39707207679748535, -0.5277277231216431,
               -0.34141218662261963, 0.04325193166732788],
              [0.013309136033058167, 0.4192518889904022, -0.5023499131202698, 0.6576784253120422, 0.08050815761089325,
               -0.5654198527336121, -0.032888151705265045, -0.004960000514984131, 0.6651177406311035,
               0.05326974391937256, -0.6230878233909607, 0.4291330575942993, 0.23004357516765594,
               -0.042912185192108154, -1.1063454151153564, 1.6930636167526245],
              [-0.3338235318660736, 0.8286457657814026, -0.3386062681674957, 2.4818878173828125, 0.2127300202846527,
               -0.63995361328125, 0.16564610600471497, -0.43873143196105957, 0.462736040353775, -0.5913347005844116,
               -0.43395015597343445, 0.27017706632614136, -1.223729133605957, -0.6909787654876709, 0.48842477798461914,
               -0.21983671188354492]]
    res = []
    for i in range(len(center)):
        p = []
        for j in range(len(pca["cps"][0])):
            val = 0.
            for k in range(len(center[0])):
                val += (center[i][k] - pca["mean"][k]) * pca["cps"][k][j]
            p.append(val)
        res.append(p)
    print(res)


class EmbeddingCenter(nn.Module):
    def __init__(self):
        super().__init__()
        param_list = []
        for i in range(3):
            param_list.append(nn.Parameter(torch.randn(4)))
        self.param_list = nn.ParameterList(param_list)

    def forward(self):
        loss = []
        for i in range(3):
            loss.append(F.softmax(self.param_list[i], 0)[:, None] * torch.ones_like(self.param_list[i][:, None]))
        loss = torch.stack(loss, -1).mean()
        yield loss


def fit_center():
    model = EmbeddingCenter()
    model.cuda()
    loss_total = 23333
    loss_tol = 0.0001
    lr = 1e-3
    opt = torch.optim.Adam(model.param_list, lr=lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0., amsgrad=True)

    step = 0.
    while loss_total > loss_tol:
        loss_total = 0.
        step += 1
        for loss in model():
            opt.zero_grad()

            loss.backward()
            opt.step()
            loss_total += loss
            print(f"step {step}", loss, loss_total)
        print(f"step =============================================")


def test_2():
    model = EmbeddingCenter()


if __name__ == "__main__":
    # x = [[1, 2, 3], [4, 2, 1], [8, 9, 10]]
    # test(x);
    fit_center();
